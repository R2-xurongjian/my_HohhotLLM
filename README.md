# HohhotLLM
Urban Large Language Model for Hohhot (å‘¼å’Œæµ©ç‰¹åŸå¸‚å¤§æ¨¡å‹)
## Urban Large Language Model for Hohhot (å‘¼å’Œæµ©ç‰¹åŸå¸‚å¤§æ¨¡å‹)
å›½å†…åœ¨å‚ç›´é¢†åŸŸå¤§æ¨¡å‹çš„ç ”ç©¶æ–¹é¢å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚éšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„ä¸æ–­å‘å±•å’Œè®¡ç®—èƒ½åŠ›çš„æå‡ï¼Œè¶Šæ¥è¶Šå¤šçš„ç ”ç©¶è€…å¼€å§‹å…³æ³¨å¦‚ä½•åˆ©ç”¨å¤§æ¨¡å‹æ¥è§£å†³ç‰¹å®šé¢†åŸŸçš„é—®é¢˜ã€‚
æœ¬é¡¹ç›®åŸºäºLangchainä¸ºåŸºç¡€ï¼Œç»“åˆLLMå¤§è¯­è¨€æ¨¡å‹ï¼Œå¹¶ä»¥ä¸°å¯Œçš„å‘¼å’Œæµ©ç‰¹åŸå¸‚æ•°æ®ä¸ºåŸºç¡€æ„å»ºäº†æœ¬åœ°é—®ç­”çŸ¥è¯†åº“æ¥å®£ä¼ å‘¼å’Œæµ©ç‰¹çš„åŸå¸‚æ–‡åŒ–ã€‚
* LangChainæ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ChatGPTï¼‰ç”¨äºæ„å»ºç«¯åˆ°ç«¯è¯­è¨€æ¨¡å‹åº”ç”¨çš„Pythonæ¡†æ¶ã€‚[Langchain](https://github.com/langchain-ai/langchain)    
* ç»è¿‡ç™¾ä¸‡è§„æ¨¡å¿ƒç†å’¨è¯¢é¢†åŸŸä¸­æ–‡é•¿æ–‡æœ¬æŒ‡ä»¤ä¸å¤šè½®å…±æƒ…å¯¹è¯æ•°æ®è”åˆæŒ‡ä»¤å¾®è°ƒçš„ [InternLMå¤§è¯­è¨€æ¨¡å‹](https://github.com/InternLM/InternLM)   

æˆ‘ä»¬æœŸæœ›ï¼Œ**Langchainæ„å»ºæœ¬åœ°çŸ¥è¯†åº“** å¯ä»¥å¸®åŠ©å­¦æœ¯ç•ŒåŠ é€Ÿå¤§æ¨¡å‹åœ¨ç‰¹å®šåŒºåŸŸæ–‡åŒ–å®£ä¼ çš„ç ”ç©¶ä¸åº”ç”¨ã€‚æœ¬é¡¹ç›®ä¸º **Urban Large Language Model for Hohhot** ã€‚
## æœ€è¿‘æ›´æ–°
- ğŸ‘ğŸ»  2024.3.08ï¼šæˆ‘ä»¬çš„å‘¼å’Œæµ©ç‰¹åŸå¸‚æ–‡åŒ–å¤§æ¨¡å‹æ­£å¼å‘å¸ƒï¼ï¼ï¼
## ç®€ä»‹
   åœ¨å­¦æœ¯ç•Œï¼Œä¸€äº›ç ”ç©¶å›¢é˜Ÿå¼€å§‹å°è¯•å°†Langchainçš„æ€æƒ³åº”ç”¨äºæœ¬åœ°çŸ¥è¯†åº“çš„æ„å»ºã€‚ä»–ä»¬è‡´åŠ›äºé€šè¿‡æ„å»ºçŸ¥è¯†å›¾è°±ã€æ•´åˆé¢†åŸŸä¸“å®¶çŸ¥è¯†ç­‰æ–¹å¼ï¼Œå»ºç«‹èµ·ä¸°å¯Œçš„æœ¬åœ°çŸ¥è¯†åº“ï¼Œå¹¶ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé—®é¢˜å›ç­”ã€‚è¿™äº›ç ”ç©¶æ—¨åœ¨æé«˜é—®ç­”ç³»ç»Ÿå¯¹ä¸­æ–‡è¯­å¢ƒçš„ç†è§£å’Œå¤„ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†ä¸ç¤¾ä¼šäººæ–‡è®¡ç®—å®éªŒå®¤ä½¿ç”¨Langchainæ„å»ºäº†ä¸€ä¸ªåä¸ºâ€œæ–‡å¿ƒä¸€è¨€â€çš„èŠå¤©æœºå™¨äººã€‚è¯¥æœºå™¨äººé›†æˆäº†å¤šç§NLPæŠ€æœ¯ï¼ŒåŒ…æ‹¬æ–‡æœ¬ç”Ÿæˆã€è¯­ä¹‰ç†è§£ã€æƒ…æ„Ÿåˆ†æç­‰ï¼Œèƒ½å¤Ÿä¸ç”¨æˆ·è¿›è¡Œè‡ªç„¶ã€æµç•…çš„å¯¹è¯ï¼Œå¹¶æä¾›å„ç§ä¿¡æ¯å’ŒæœåŠ¡ã€‚æœ¬æ–‡å°±æ˜¯åŸºäºLangchainæ¡†æ¶æ„å»ºæœ¬åœ°çš„çŸ¥è¯†åº“å¹¶æ¥å…¥LLMæ¨¡å‹æ¥æ„å»ºçš„ä¸€ä¸ªå¯¹è¯é—®ç­”ç³»ç»Ÿ
<p align="center">
    <img src="./figure/Langchain.jpeg" width=900px/>
</p>

æˆ‘ä»¬é€‰æ‹©äº† [InternLMå¤§è¯­è¨€æ¨¡å‹](https://github.com/InternLM/InternLM) ä½œä¸ºåº•åº§å¤§è¯­è¨€æ¨¡å‹ï¼Œè¿›è¡Œäº†**æœ¬åœ°çŸ¥è¯†åº“çš„æ¥å…¥**ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„é’ˆå¯¹å‘¼å’Œæµ©ç‰¹åœ°åŒºçš„äº¤æµé—®ç­”èƒ½åŠ›ã€‚

## ä½¿ç”¨æ–¹æ³•
* å…‹éš†æœ¬é¡¹ç›®
```bash
cd ~
git clone https://github.com/R2-xurongjian/my_HohhotLLM.git
```
* ä¸‹è½½æ¨¡å‹    
æœ¬é¡¹ç›®ä½¿ç”¨çš„LLMæ¨¡å‹ä¸ºå¤æ—¦å¤§å­¦ç ”å‘çš„InternLMï¼ˆä¹¦ç”ŸÂ·æµ¦è¯­ï¼‰å¤§è¯­è¨€æ¨¡å‹ï¼Œå»ºè®®æ‰‹åŠ¨åœ¨huggingfaceä¸Šä¸‹è½½æ¨¡å‹ä¹Ÿå¯ä»¥gitä¸‹è½½
```
git clone https://huggingface.co/internlm/internlm2-chat-7b
```

* åˆ›å»ºå¹¶æ¿€æ´»condaç¯å¢ƒ    
è¿™é‡Œæˆ‘ä¸åšå…·ä½“çš„è™šæ‹Ÿcondaç¯å¢ƒçš„åˆ›å»º
```
conda activate InternLM
```

* å®‰è£…Langchainç›¸å…³ä¾èµ–
```
pip install langchain==0.0.292
pip install gradio==4.4.0
pip install chromadb==0.4.15
pip install sentence-transformers==2.2.2
pip install unstructured==0.10.30
pip install markdown==3.3.7
```
* ä¸‹è½½å¼€æºè¯å‘é‡æ¨¡å‹    
åŒæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨åˆ°å¼€æºè¯å‘é‡æ¨¡å‹ [Sentence Transformer](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2):ï¼ˆæˆ‘ä»¬ä¹Ÿå¯ä»¥é€‰ç”¨åˆ«çš„å¼€æºè¯å‘é‡æ¨¡å‹æ¥è¿›è¡Œ Embeddingï¼Œç›®å‰é€‰ç”¨è¿™ä¸ªæ¨¡å‹æ˜¯ç›¸å¯¹    è½»é‡ã€æ”¯æŒä¸­æ–‡ä¸”æ•ˆæœè¾ƒå¥½çš„ï¼‰

* é¦–å…ˆéœ€è¦ä½¿ç”¨ `huggingface` å®˜æ–¹æä¾›çš„ `huggingface-cli` å‘½ä»¤è¡Œå·¥å…·ã€‚å®‰è£…ä¾èµ–:

```
pip install -U huggingface_hub
```

* ç„¶ååœ¨æ ¹ç›®å½•ä¸‹æ–°å»ºpythonæ–‡ä»¶ `download.py`ï¼Œå¡«å…¥ä»¥ä¸‹ä»£ç ï¼š
```python
import os
* è¿è¡Œdownload.pyè¿›è¡Œä¸‹è½½

# ä¸‹è½½æ¨¡å‹
os.system('huggingface-cli download --resume-download sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 --local-dir /root/data/model/sentence-transformer')
```
* å®‰è£…è¿è¡Œdemoæ‰€éœ€è¦çš„ä¾èµ–
```shell
# å‡çº§pip
python -m pip install --upgrade pip

pip install modelscope==1.9.5
pip install transformers==4.35.2
pip install streamlit==1.24.0
pip install sentencepiece==0.1.99
pip install accelerate==0.24.1
```
   
* å¯åŠ¨æœåŠ¡     
æœ¬é¡¹ç›®æä¾›äº†[run_gradio.py](./run_gradio.py)ä½œä¸ºæ¨¡å‹çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œæ¥é€šè¿‡ python å‘½ä»¤è¿è¡Œï¼Œå³å¯åœ¨æœ¬åœ°å¯åŠ¨çŸ¥è¯†åº“åŠ©æ‰‹çš„ Web Demoï¼Œé»˜è®¤ä¼šåœ¨ 7860 ç«¯å£è¿è¡Œï¼Œæ¥ä¸‹æ¥å°†æœåŠ¡å™¨ç«¯å£æ˜ å°„åˆ°æœ¬åœ°ç«¯å£å³å¯è®¿é—®
```
python run_gradio.py
```

## ç¤ºä¾‹
* æ•´ä½“å¸ƒå±€
<p align="center">
    <img src="./figure/æ•´ä½“å¸ƒå±€.png" width=900px/>
</p>  

* æ ·ä¾‹1ï¼šä»‹ç»ä¸€ä¸‹å‘¼å’Œæµ©ç‰¹çš„æ–‡åŒ–
<p align="center">
    <img src="./figure/æ–‡åŒ–.png" width=900px/>
</p>

* æ ·ä¾‹2ï¼šä»‹ç»ä¸€ä¸‹å‘¼å’Œæµ©ç‰¹çš„å¤§æ˜­å¯º

<p align="center">
    <img src="./figure/å¤§æ˜­å¯º.png" width=900px/>
</p>

* æ ·ä¾‹3ï¼šå†…è’™å¤å¤§å­¦åœ¨å‘¼å’Œæµ©ç‰¹çš„ä½ç½®

<p align="center">
    <img src="./figure/å†…è’™å¤å¤§å¾ä¹Ÿ.png" width=900px/>
</p>


## å£°æ˜
* æœ¬é¡¹ç›®ä½¿ç”¨äº†ChatGLM-6B æ¨¡å‹çš„æƒé‡ï¼Œéœ€è¦éµå¾ªå…¶[MODEL_LICENSE](https://github.com/THUDM/ChatGLM-6B/blob/main/MODEL_LICENSE)ï¼Œå› æ­¤ï¼Œ**æœ¬é¡¹ç›®ä»…å¯ç”¨äºæ‚¨çš„éå•†ä¸šç ”ç©¶ç›®çš„**ã€‚
* æœ¬é¡¹ç›®æä¾›çš„SoulChatæ¨¡å‹è‡´åŠ›äºæå‡å¤§æ¨¡å‹çš„å…±æƒ…å¯¹è¯ä¸å€¾å¬èƒ½åŠ›ï¼Œç„¶è€Œï¼Œæ¨¡å‹çš„è¾“å‡ºæ–‡æœ¬å…·æœ‰ä¸€å®šçš„éšæœºæ€§ï¼Œå½“å…¶ä½œä¸ºä¸€ä¸ªå€¾å¬è€…çš„æ—¶å€™ï¼Œæ˜¯åˆé€‚çš„ï¼Œä½†æ˜¯ä¸å»ºè®®å°†SoulChatæ¨¡å‹çš„è¾“å‡ºæ–‡æœ¬æ›¿ä»£å¿ƒç†åŒ»ç”Ÿç­‰çš„è¯Šæ–­ã€å»ºè®®ã€‚æœ¬é¡¹ç›®ä¸ä¿è¯æ¨¡å‹è¾“å‡ºçš„æ–‡æœ¬å®Œå…¨é€‚åˆäºç”¨æˆ·ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨æœ¬æ¨¡å‹æ—¶éœ€è¦æ‰¿æ‹…å…¶å¸¦æ¥çš„æ‰€æœ‰é£é™©ï¼
* æ‚¨ä¸å¾—å‡ºäºä»»ä½•å•†ä¸šã€å†›äº‹æˆ–éæ³•ç›®çš„ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆå¹¶ã€å‘å¸ƒã€åˆ†å‘ã€å¤åˆ¶æˆ–åˆ›å»ºSoulChatæ¨¡å‹çš„å…¨éƒ¨æˆ–éƒ¨åˆ†è¡ç”Ÿä½œå“ã€‚
* æ‚¨ä¸å¾—åˆ©ç”¨SoulChatæ¨¡å‹ä»äº‹ä»»ä½•å±å®³å›½å®¶å®‰å…¨å’Œå›½å®¶ç»Ÿä¸€ã€å±å®³ç¤¾ä¼šå…¬å…±åˆ©ç›Šã€ä¾µçŠ¯äººèº«æƒç›Šçš„è¡Œä¸ºã€‚
* æ‚¨åœ¨ä½¿ç”¨SoulChatæ¨¡å‹æ—¶åº”çŸ¥æ‚‰ï¼Œå…¶ä¸èƒ½æ›¿ä»£åŒ»ç”Ÿã€å¿ƒç†åŒ»ç”Ÿç­‰ä¸“ä¸šäººå£«ï¼Œä¸åº”è¿‡åº¦ä¾èµ–ã€æœä»ã€ç›¸ä¿¡æ¨¡å‹çš„è¾“å‡ºï¼Œä¸èƒ½é•¿æœŸæ²‰è¿·äºä¸SoulChatæ¨¡å‹èŠå¤©ã€‚

## è‡´è°¢
æœ¬é¡¹ç›®ç”±[åå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢](https://www2.scut.edu.cn/ft/main.htm) å¹¿ä¸œçœæ•°å­—å­ªç”Ÿäººé‡ç‚¹å®éªŒå®¤å‘èµ·ï¼Œå¾—åˆ°äº†åå—ç†å·¥å¤§å­¦ä¿¡æ¯ç½‘ç»œå·¥ç¨‹ç ”ç©¶ä¸­å¿ƒã€ç”µå­ä¸ä¿¡æ¯å­¦é™¢ç­‰å­¦é™¢éƒ¨é—¨çš„æ”¯æ’‘ï¼ŒåŒæ—¶è‡´è°¢å¹¿ä¸œçœå¦‡å¹¼ä¿å¥é™¢ã€å¹¿å·å¸‚å¦‡å¥³å„¿ç«¥åŒ»ç–—ä¸­å¿ƒã€ä¸­å±±å¤§å­¦é™„å±ç¬¬ä¸‰åŒ»é™¢ã€åˆè‚¥ç»¼åˆæ€§å›½å®¶ç§‘å­¦ä¸­å¿ƒäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ç­‰åˆä½œå•ä½ã€‚

åŒæ—¶ï¼Œæˆ‘ä»¬æ„Ÿè°¢ä»¥ä¸‹åª’ä½“æˆ–å…¬ä¼—å·å¯¹æœ¬é¡¹ç›®çš„æŠ¥é“ï¼ˆæ’åä¸åˆ†å…ˆåï¼‰ï¼š
* åª’ä½“æŠ¥é“
  [äººæ°‘æ—¥æŠ¥](https://wap.peopleapp.com/article/rmh36174922/rmh36174922)ã€[ä¸­å›½ç½‘](https://hs.china.com.cn/gd/83980.html)ã€[å…‰æ˜ç½‘](https://health.gmw.cn/2023-06/13/content_36628062.htm)ã€[TOMç§‘æŠ€](https://tech.tom.com/202306/4526869977.html)ã€[æœªæ¥ç½‘](http://www.zzfuture.cn/news/956.html)ã€[å¤§ä¼—ç½‘](http://linyi.dzwww.com.3xw.site/xinwen/202306/t20230613_202306135667.htm)ã€[ä¸­å›½å‘å±•æŠ¥é“ç½‘](http://www.chinafzbdw.com/computer/13149.html?1686564408)ã€[ä¸­å›½æ—¥æŠ¥ç½‘](http://energy.chinaduily.com.cn/c/2023/15205.html)ã€[æ–°åèµ„è®¯ç½‘](http://www.xinhuazxun.com/world/21762.html?1686564382)ã€[ä¸­åç½‘](https://life.china.com/2023-06/12/content_215815.html)ã€[ä»Šæ—¥å¤´æ¡](https://www.toutiao.com/article/7243412314223952418/)ã€[æœç‹](https://www.sohu.com/a/684501109_120159010)ã€[è…¾è®¯æ–°é—»](https://page.om.qq.com/page/OhSXIMEUtDtdg0rTi6aAoTbg0)ã€[ç½‘æ˜“æ–°é—»](https://www.163.com/dy/article/I70BJ9U00552UJUX.html)ã€[ä¸­å›½èµ„è®¯ç½‘](http://www.chinazxun.com/world/23252.html?1686564532)ã€[ä¸­å›½ä¼ æ’­ç½‘](http://www.chinachbo.com/a/view/11697.html?1686564509)ã€[ä¸­å›½éƒ½å¸‚æŠ¥é“ç½‘](http://www.zgdsbdw.com/meida/11273.html?1686564485)ã€[ä¸­ååŸå¸‚ç½‘](http://www.zhcsww.com/hot/2023/0612/9609.html?1686564434)

* å…¬ä¼—å·
  [å¹¿ä¸œå®éªŒå®¤å»ºè®¾](https://mp.weixin.qq.com/s/gemlKfLg8c-AtjiV7uTUTQ)ã€[æ™ºèƒ½è¯­éŸ³æ–°é’å¹´](https://mp.weixin.qq.com/s/vBMKXUJoAIywkXY2nY60eA)ã€[æ·±åº¦å­¦ä¹ ä¸NLP](https://mp.weixin.qq.com/s/qSHLT8FbvohZESp-UCah6g)ã€[AINLP](https://mp.weixin.qq.com/s/EX3f9WblLKM8K_nSwhno_g)

## å¼•ç”¨
```bib
@inproceedings{chen-etal-2023-soulchat,
    title = "{S}oul{C}hat: Improving {LLM}s{'} Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations",
    author = "Chen, Yirong  and
      Xing, Xiaofen  and
      Lin, Jingkai  and
      Zheng, Huimin  and
      Wang, Zhenyu  and
      Liu, Qi  and
      Xu, Xiangmin",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.83",
    pages = "1170--1183",
    abstract = "Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.",
}
}
```
