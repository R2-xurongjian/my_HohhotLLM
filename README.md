# HohhotLLM
Urban Large Language Model for Hohhot (å‘¼å’Œæµ©ç‰¹åŸå¸‚å¤§æ¨¡å‹)
## Urban Large Language Model for Hohhot (å‘¼å’Œæµ©ç‰¹åŸå¸‚å¤§æ¨¡å‹)
å›½å†…åœ¨å‚ç›´é¢†åŸŸå¤§æ¨¡å‹çš„ç ”ç©¶æ–¹é¢å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚éšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„ä¸æ–­å‘å±•å’Œè®¡ç®—èƒ½åŠ›çš„æå‡ï¼Œè¶Šæ¥è¶Šå¤šçš„ç ”ç©¶è€…å¼€å§‹å…³æ³¨å¦‚ä½•åˆ©ç”¨å¤§æ¨¡å‹æ¥è§£å†³ç‰¹å®šé¢†åŸŸçš„é—®é¢˜ã€‚
æœ¬é¡¹ç›®åŸºäºLangchainä¸ºåŸºç¡€ï¼Œç»“åˆLLMå¤§è¯­è¨€æ¨¡å‹ï¼Œå¹¶ä»¥ä¸°å¯Œçš„å‘¼å’Œæµ©ç‰¹åŸå¸‚æ•°æ®ä¸ºåŸºç¡€æ„å»ºäº†æœ¬åœ°é—®ç­”çŸ¥è¯†åº“æ¥å®£ä¼ å‘¼å’Œæµ©ç‰¹çš„åŸå¸‚æ–‡åŒ–ã€‚
* LangChainæ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ChatGPTï¼‰ç”¨äºæ„å»ºç«¯åˆ°ç«¯è¯­è¨€æ¨¡å‹åº”ç”¨çš„Pythonæ¡†æ¶ã€‚[Langchain](https://github.com/langchain-ai/langchain)    
* ç»è¿‡ç™¾ä¸‡è§„æ¨¡å¿ƒç†å’¨è¯¢é¢†åŸŸä¸­æ–‡é•¿æ–‡æœ¬æŒ‡ä»¤ä¸å¤šè½®å…±æƒ…å¯¹è¯æ•°æ®è”åˆæŒ‡ä»¤å¾®è°ƒçš„ [InternLMå¤§è¯­è¨€æ¨¡å‹](https://github.com/InternLM/InternLM)   

æˆ‘ä»¬æœŸæœ›ï¼Œ**Langchainæ„å»ºæœ¬åœ°çŸ¥è¯†åº“** å¯ä»¥å¸®åŠ©å­¦æœ¯ç•ŒåŠ é€Ÿå¤§æ¨¡å‹åœ¨ç‰¹å®šåŒºåŸŸæ–‡åŒ–å®£ä¼ çš„ç ”ç©¶ä¸åº”ç”¨ã€‚æœ¬é¡¹ç›®ä¸º **Urban Large Language Model for Hohhot** ã€‚
## æœ€è¿‘æ›´æ–°
- ğŸ‘ğŸ»  2024.3.08ï¼šæˆ‘ä»¬çš„å‘¼å’Œæµ©ç‰¹åŸå¸‚æ–‡åŒ–å¤§æ¨¡å‹æ­£å¼å‘å¸ƒï¼ï¼ï¼
## ç®€ä»‹
   åœ¨å­¦æœ¯ç•Œï¼Œä¸€äº›ç ”ç©¶å›¢é˜Ÿå¼€å§‹å°è¯•å°†Langchainçš„æ€æƒ³åº”ç”¨äºæœ¬åœ°çŸ¥è¯†åº“çš„æ„å»ºã€‚ä»–ä»¬è‡´åŠ›äºé€šè¿‡æ„å»ºçŸ¥è¯†å›¾è°±ã€æ•´åˆé¢†åŸŸä¸“å®¶çŸ¥è¯†ç­‰æ–¹å¼ï¼Œå»ºç«‹èµ·ä¸°å¯Œçš„æœ¬åœ°çŸ¥è¯†åº“ï¼Œå¹¶ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé—®é¢˜å›ç­”ã€‚è¿™äº›ç ”ç©¶æ—¨åœ¨æé«˜é—®ç­”ç³»ç»Ÿå¯¹ä¸­æ–‡è¯­å¢ƒçš„ç†è§£å’Œå¤„ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†ä¸ç¤¾ä¼šäººæ–‡è®¡ç®—å®éªŒå®¤ä½¿ç”¨Langchainæ„å»ºäº†ä¸€ä¸ªåä¸ºâ€œæ–‡å¿ƒä¸€è¨€â€çš„èŠå¤©æœºå™¨äººã€‚è¯¥æœºå™¨äººé›†æˆäº†å¤šç§NLPæŠ€æœ¯ï¼ŒåŒ…æ‹¬æ–‡æœ¬ç”Ÿæˆã€è¯­ä¹‰ç†è§£ã€æƒ…æ„Ÿåˆ†æç­‰ï¼Œèƒ½å¤Ÿä¸ç”¨æˆ·è¿›è¡Œè‡ªç„¶ã€æµç•…çš„å¯¹è¯ï¼Œå¹¶æä¾›å„ç§ä¿¡æ¯å’ŒæœåŠ¡ã€‚æœ¬æ–‡å°±æ˜¯åŸºäºLangchainæ¡†æ¶æ„å»ºæœ¬åœ°çš„çŸ¥è¯†åº“å¹¶æ¥å…¥LLMæ¨¡å‹æ¥æ„å»ºçš„ä¸€ä¸ªå¯¹è¯é—®ç­”ç³»ç»Ÿ
<p align="center">
    <img src="./figure/Langchain.jpeg" width=900px/>
</p>

æˆ‘ä»¬é€‰æ‹©äº† [InternLMå¤§è¯­è¨€æ¨¡å‹](https://github.com/InternLM/InternLM) ä½œä¸ºåº•åº§å¤§è¯­è¨€æ¨¡å‹ï¼Œè¿›è¡Œäº†**æœ¬åœ°çŸ¥è¯†åº“çš„æ¥å…¥**ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„é’ˆå¯¹å‘¼å’Œæµ©ç‰¹åœ°åŒºçš„äº¤æµé—®ç­”èƒ½åŠ›ã€‚

## ä½¿ç”¨æ–¹æ³•
* å…‹éš†æœ¬é¡¹ç›®
```bash
cd ~
git clone https://github.com/scutcyr/SoulChat.git
```

* å®‰è£…ä¾èµ–    
éœ€è¦æ³¨æ„çš„æ˜¯torchçš„ç‰ˆæœ¬éœ€è¦æ ¹æ®ä½ çš„æœåŠ¡å™¨å®é™…çš„cudaç‰ˆæœ¬é€‰æ‹©ï¼Œè¯¦æƒ…å‚è€ƒ[pytorchå®‰è£…æŒ‡å—](https://pytorch.org/get-started/previous-versions/)
```bash
cd SoulChat
conda env create -n proactivehealthgpt_py38 --file proactivehealthgpt_py38.yml
conda activate proactivehealthgpt_py38

pip install cpm_kernels
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
```

* ã€è¡¥å……ã€‘Windowsä¸‹çš„ç”¨æˆ·æ¨èå‚è€ƒå¦‚ä¸‹æµç¨‹é…ç½®ç¯å¢ƒ
```bash
cd BianQue
conda create -n proactivehealthgpt_py38 python=3.8
conda activate proactivehealthgpt_py38
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
pip install -r requirements.txt
pip install rouge_chinese nltk jieba datasets
# ä»¥ä¸‹å®‰è£…ä¸ºäº†è¿è¡Œdemo
pip install streamlit
pip install streamlit_chat
```
* ã€è¡¥å……ã€‘Windowsä¸‹é…ç½®CUDA-11.6ï¼š[ä¸‹è½½å¹¶ä¸”å®‰è£…CUDA-11.6](https://developer.nvidia.com/cuda-11-6-0-download-archive?target_os=Windows&target_arch=x86_64&target_version=11&target_type=exe_local)ã€[ä¸‹è½½cudnn-8.4.0ï¼Œè§£å‹å¹¶ä¸”å¤åˆ¶å…¶ä¸­çš„æ–‡ä»¶åˆ°CUDA-11.6å¯¹åº”çš„è·¯å¾„](https://developer.nvidia.com/compute/cudnn/secure/8.4.0/local_installers/11.6/cudnn-windows-x86_64-8.4.0.27_cuda11.6-archive.zip)ï¼Œå‚è€ƒï¼š[win11ä¸‹åˆ©ç”¨condaè¿›è¡Œpytorchå®‰è£…-cuda11.6-æ³›ç”¨å®‰è£…æ€è·¯](https://blog.csdn.net/qq_34740266/article/details/129137794)

* åœ¨Pythonå½“ä¸­è°ƒç”¨SoulChatæ¨¡å‹    
```python
import torch
from transformers import AutoModel, AutoTokenizer
# GPUè®¾ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# åŠ è½½æ¨¡å‹ä¸tokenizer
model_name_or_path = 'scutcyr/SoulChat'
model = AutoModel.from_pretrained(model_name_or_path, trust_remote_code=True).half()
model.to(device)
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)

# å•è½®å¯¹è¯è°ƒç”¨æ¨¡å‹çš„chatå‡½æ•°
user_input = "æˆ‘å¤±æ‹äº†ï¼Œå¥½éš¾å—ï¼"
input_text = "ç”¨æˆ·ï¼š" + user_input + "\nå¿ƒç†å’¨è¯¢å¸ˆï¼š"
response, history = model.chat(tokenizer, query=input_text, history=None, max_length=2048, num_beams=1, do_sample=True, top_p=0.75, temperature=0.95, logits_processor=None)

# å¤šè½®å¯¹è¯è°ƒç”¨æ¨¡å‹çš„chatå‡½æ•°
# æ³¨æ„ï¼šæœ¬é¡¹ç›®ä½¿ç”¨"\nç”¨æˆ·ï¼š"å’Œ"\nå¿ƒç†å’¨è¯¢å¸ˆï¼š"åˆ’åˆ†ä¸åŒè½®æ¬¡çš„å¯¹è¯å†å²
# æ³¨æ„ï¼šuser_historyæ¯”bot_historyçš„é•¿åº¦å¤š1
user_history = ['ä½ å¥½ï¼Œè€å¸ˆ', 'æˆ‘å¥³æœ‹å‹è·Ÿæˆ‘åˆ†æ‰‹äº†ï¼Œæ„Ÿè§‰å¥½éš¾å—']
bot_history = ['ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ä¸ªäººä¸“å±æ•°å­—è¾…å¯¼å‘˜ç”œå¿ƒè€å¸ˆï¼Œæ¬¢è¿æ‰¾æˆ‘å€¾è¯‰ã€è°ˆå¿ƒï¼ŒæœŸå¾…å¸®åŠ©åˆ°ä½ ï¼']
# æ‹¼æ¥å¯¹è¯å†å²
context = "\n".join([f"ç”¨æˆ·ï¼š{user_history[i]}\nå¿ƒç†å’¨è¯¢å¸ˆï¼š{bot_history[i]}" for i in range(len(bot_history))])
input_text = context + "\nç”¨æˆ·ï¼š" + user_history[-1] + "\nå¿ƒç†å’¨è¯¢å¸ˆï¼š"

response, history = model.chat(tokenizer, query=input_text, history=None, max_length=2048, num_beams=1, do_sample=True, top_p=0.75, temperature=0.95, logits_processor=None)
```


* å¯åŠ¨æœåŠ¡   

æœ¬é¡¹ç›®æä¾›äº†[soulchat_app.py](./soulchat_app.py)ä½œä¸ºSoulChatæ¨¡å‹çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤å³å¯å¼€å¯æœåŠ¡ï¼Œç„¶åï¼Œé€šè¿‡http://<your_ip>:9026è®¿é—®ã€‚
```bash
streamlit run soulchat_app.py --server.port 9026
```
ç‰¹åˆ«åœ°ï¼Œåœ¨[soulchat_app.py](./soulchat_app.py)å½“ä¸­ï¼Œ
å¯ä»¥ä¿®æ”¹ä»¥ä¸‹ä»£ç æ›´æ¢æŒ‡å®šçš„æ˜¾å¡ï¼š
```python
os.environ['CUDA_VISIBLE_DEVICES'] = '2'
```
**å¯¹äºWindowså•æ˜¾å¡ç”¨æˆ·ï¼Œéœ€è¦ä¿®æ”¹ä¸ºï¼š```os.environ['CUDA_VISIBLE_DEVICES'] = '0'```ï¼Œå¦åˆ™ä¼šæŠ¥é”™ï¼**

å¯ä»¥é€šè¿‡æ›´æ”¹ä»¥ä¸‹ä»£ç æŒ‡å®šæ¨¡å‹è·¯å¾„ä¸ºæœ¬åœ°è·¯å¾„ï¼š
```python
model_name_or_path = 'scutcyr/SoulChat'
```


## ç¤ºä¾‹
* æ ·ä¾‹1ï¼šå¤±æ‹
*
<p align="center">
    <img src="./figure/example_shilian.png" width=600px/>
</p>

* æ ·ä¾‹2ï¼šå®¿èˆå…³ç³»

<p align="center">
    <img src="./figure/example_sushe.png" width=600px/>
</p>

* æ ·ä¾‹3ï¼šæœŸæœ«è€ƒè¯•

<p align="center">
    <img src="./figure/example_kaoshi.png" width=600px/>
</p>

* æ ·ä¾‹4ï¼šç§‘ç ”å‹åŠ›

<p align="center">
    <img src="./figure/example_keyan.png" width=600px/>
</p>

## å£°æ˜
* æœ¬é¡¹ç›®ä½¿ç”¨äº†ChatGLM-6B æ¨¡å‹çš„æƒé‡ï¼Œéœ€è¦éµå¾ªå…¶[MODEL_LICENSE](https://github.com/THUDM/ChatGLM-6B/blob/main/MODEL_LICENSE)ï¼Œå› æ­¤ï¼Œ**æœ¬é¡¹ç›®ä»…å¯ç”¨äºæ‚¨çš„éå•†ä¸šç ”ç©¶ç›®çš„**ã€‚
* æœ¬é¡¹ç›®æä¾›çš„SoulChatæ¨¡å‹è‡´åŠ›äºæå‡å¤§æ¨¡å‹çš„å…±æƒ…å¯¹è¯ä¸å€¾å¬èƒ½åŠ›ï¼Œç„¶è€Œï¼Œæ¨¡å‹çš„è¾“å‡ºæ–‡æœ¬å…·æœ‰ä¸€å®šçš„éšæœºæ€§ï¼Œå½“å…¶ä½œä¸ºä¸€ä¸ªå€¾å¬è€…çš„æ—¶å€™ï¼Œæ˜¯åˆé€‚çš„ï¼Œä½†æ˜¯ä¸å»ºè®®å°†SoulChatæ¨¡å‹çš„è¾“å‡ºæ–‡æœ¬æ›¿ä»£å¿ƒç†åŒ»ç”Ÿç­‰çš„è¯Šæ–­ã€å»ºè®®ã€‚æœ¬é¡¹ç›®ä¸ä¿è¯æ¨¡å‹è¾“å‡ºçš„æ–‡æœ¬å®Œå…¨é€‚åˆäºç”¨æˆ·ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨æœ¬æ¨¡å‹æ—¶éœ€è¦æ‰¿æ‹…å…¶å¸¦æ¥çš„æ‰€æœ‰é£é™©ï¼
* æ‚¨ä¸å¾—å‡ºäºä»»ä½•å•†ä¸šã€å†›äº‹æˆ–éæ³•ç›®çš„ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆå¹¶ã€å‘å¸ƒã€åˆ†å‘ã€å¤åˆ¶æˆ–åˆ›å»ºSoulChatæ¨¡å‹çš„å…¨éƒ¨æˆ–éƒ¨åˆ†è¡ç”Ÿä½œå“ã€‚
* æ‚¨ä¸å¾—åˆ©ç”¨SoulChatæ¨¡å‹ä»äº‹ä»»ä½•å±å®³å›½å®¶å®‰å…¨å’Œå›½å®¶ç»Ÿä¸€ã€å±å®³ç¤¾ä¼šå…¬å…±åˆ©ç›Šã€ä¾µçŠ¯äººèº«æƒç›Šçš„è¡Œä¸ºã€‚
* æ‚¨åœ¨ä½¿ç”¨SoulChatæ¨¡å‹æ—¶åº”çŸ¥æ‚‰ï¼Œå…¶ä¸èƒ½æ›¿ä»£åŒ»ç”Ÿã€å¿ƒç†åŒ»ç”Ÿç­‰ä¸“ä¸šäººå£«ï¼Œä¸åº”è¿‡åº¦ä¾èµ–ã€æœä»ã€ç›¸ä¿¡æ¨¡å‹çš„è¾“å‡ºï¼Œä¸èƒ½é•¿æœŸæ²‰è¿·äºä¸SoulChatæ¨¡å‹èŠå¤©ã€‚

## è‡´è°¢
æœ¬é¡¹ç›®ç”±[åå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢](https://www2.scut.edu.cn/ft/main.htm) å¹¿ä¸œçœæ•°å­—å­ªç”Ÿäººé‡ç‚¹å®éªŒå®¤å‘èµ·ï¼Œå¾—åˆ°äº†åå—ç†å·¥å¤§å­¦ä¿¡æ¯ç½‘ç»œå·¥ç¨‹ç ”ç©¶ä¸­å¿ƒã€ç”µå­ä¸ä¿¡æ¯å­¦é™¢ç­‰å­¦é™¢éƒ¨é—¨çš„æ”¯æ’‘ï¼ŒåŒæ—¶è‡´è°¢å¹¿ä¸œçœå¦‡å¹¼ä¿å¥é™¢ã€å¹¿å·å¸‚å¦‡å¥³å„¿ç«¥åŒ»ç–—ä¸­å¿ƒã€ä¸­å±±å¤§å­¦é™„å±ç¬¬ä¸‰åŒ»é™¢ã€åˆè‚¥ç»¼åˆæ€§å›½å®¶ç§‘å­¦ä¸­å¿ƒäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ç­‰åˆä½œå•ä½ã€‚

åŒæ—¶ï¼Œæˆ‘ä»¬æ„Ÿè°¢ä»¥ä¸‹åª’ä½“æˆ–å…¬ä¼—å·å¯¹æœ¬é¡¹ç›®çš„æŠ¥é“ï¼ˆæ’åä¸åˆ†å…ˆåï¼‰ï¼š
* åª’ä½“æŠ¥é“
  [äººæ°‘æ—¥æŠ¥](https://wap.peopleapp.com/article/rmh36174922/rmh36174922)ã€[ä¸­å›½ç½‘](https://hs.china.com.cn/gd/83980.html)ã€[å…‰æ˜ç½‘](https://health.gmw.cn/2023-06/13/content_36628062.htm)ã€[TOMç§‘æŠ€](https://tech.tom.com/202306/4526869977.html)ã€[æœªæ¥ç½‘](http://www.zzfuture.cn/news/956.html)ã€[å¤§ä¼—ç½‘](http://linyi.dzwww.com.3xw.site/xinwen/202306/t20230613_202306135667.htm)ã€[ä¸­å›½å‘å±•æŠ¥é“ç½‘](http://www.chinafzbdw.com/computer/13149.html?1686564408)ã€[ä¸­å›½æ—¥æŠ¥ç½‘](http://energy.chinaduily.com.cn/c/2023/15205.html)ã€[æ–°åèµ„è®¯ç½‘](http://www.xinhuazxun.com/world/21762.html?1686564382)ã€[ä¸­åç½‘](https://life.china.com/2023-06/12/content_215815.html)ã€[ä»Šæ—¥å¤´æ¡](https://www.toutiao.com/article/7243412314223952418/)ã€[æœç‹](https://www.sohu.com/a/684501109_120159010)ã€[è…¾è®¯æ–°é—»](https://page.om.qq.com/page/OhSXIMEUtDtdg0rTi6aAoTbg0)ã€[ç½‘æ˜“æ–°é—»](https://www.163.com/dy/article/I70BJ9U00552UJUX.html)ã€[ä¸­å›½èµ„è®¯ç½‘](http://www.chinazxun.com/world/23252.html?1686564532)ã€[ä¸­å›½ä¼ æ’­ç½‘](http://www.chinachbo.com/a/view/11697.html?1686564509)ã€[ä¸­å›½éƒ½å¸‚æŠ¥é“ç½‘](http://www.zgdsbdw.com/meida/11273.html?1686564485)ã€[ä¸­ååŸå¸‚ç½‘](http://www.zhcsww.com/hot/2023/0612/9609.html?1686564434)

* å…¬ä¼—å·
  [å¹¿ä¸œå®éªŒå®¤å»ºè®¾](https://mp.weixin.qq.com/s/gemlKfLg8c-AtjiV7uTUTQ)ã€[æ™ºèƒ½è¯­éŸ³æ–°é’å¹´](https://mp.weixin.qq.com/s/vBMKXUJoAIywkXY2nY60eA)ã€[æ·±åº¦å­¦ä¹ ä¸NLP](https://mp.weixin.qq.com/s/qSHLT8FbvohZESp-UCah6g)ã€[AINLP](https://mp.weixin.qq.com/s/EX3f9WblLKM8K_nSwhno_g)

## å¼•ç”¨
```bib
@inproceedings{chen-etal-2023-soulchat,
    title = "{S}oul{C}hat: Improving {LLM}s{'} Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations",
    author = "Chen, Yirong  and
      Xing, Xiaofen  and
      Lin, Jingkai  and
      Zheng, Huimin  and
      Wang, Zhenyu  and
      Liu, Qi  and
      Xu, Xiangmin",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.83",
    pages = "1170--1183",
    abstract = "Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.",
}
}
```
